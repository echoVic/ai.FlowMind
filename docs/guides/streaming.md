# æµå¼è¾“å‡ºåŠŸèƒ½è¯´æ˜

FlowMind é¡¹ç›®æ”¯æŒ AI æ¨¡å‹çš„æµå¼è¾“å‡ºåŠŸèƒ½ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒã€‚

## ğŸš€ æµå¼è¾“å‡ºæ”¯æŒçŠ¶æ€

### âœ… å®Œå…¨æ”¯æŒæµå¼è¾“å‡º

- **OpenAI GPT ç³»åˆ—**: é€šè¿‡ `@langchain/openai` åŸç”Ÿæ”¯æŒ
- **Anthropic Claude ç³»åˆ—**: é€šè¿‡ `@langchain/anthropic` åŸç”Ÿæ”¯æŒ

### âŒ æš‚ä¸æ”¯æŒæµå¼è¾“å‡º

- **ç«å±±å¼•æ“è±†åŒ…**: è‡ªå®šä¹‰é€‚é…å™¨ï¼Œæš‚æœªå®ç°æµå¼æ”¯æŒ
- **Qwen é€šä¹‰åƒé—®**: è‡ªå®šä¹‰é€‚é…å™¨ï¼Œæš‚æœªå®ç°æµå¼æ”¯æŒ

### ğŸ”„ è‡ªåŠ¨é™çº§æœºåˆ¶

å½“æ£€æµ‹åˆ°æ¨¡å‹ä¸æ”¯æŒæµå¼è¾“å‡ºæ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é™çº§åˆ°æ™®é€šè°ƒç”¨æ¨¡å¼ï¼Œç¡®ä¿åŠŸèƒ½æ­£å¸¸è¿è¡Œã€‚

## ğŸ› ï¸ æŠ€æœ¯å®ç°

### DiagramAgent æµå¼æ”¯æŒ

```typescript
// æ”¯æŒæµå¼è¾“å‡ºçš„ç”Ÿæˆæ–¹æ³•
async generateDiagram(
  request: DiagramGenerationRequest, 
  onStream?: (chunk: string) => void  // æµå¼å›è°ƒå‡½æ•°
): Promise<DiagramGenerationResult>

// æ£€æµ‹æ¨¡å‹æ˜¯å¦æ”¯æŒæµå¼
private supportsStreaming(): boolean {
  const modelType = this.model._llmType();
  return modelType === 'openai' || modelType === 'anthropic';
}

// æµå¼è°ƒç”¨å®ç°
private async invokeModelStream(
  messages: BaseMessage[], 
  onStream: (chunk: string) => void
): Promise<string> {
  let fullContent = '';
  const stream = await this.model.stream(messages);
  
  for await (const chunk of stream) {
    const content = chunk.content as string;
    if (content) {
      fullContent += content;
      onStream(content);  // å®æ—¶å›è°ƒ
    }
  }
  
  return fullContent;
}
```

### å‰ç«¯é›†æˆ

```typescript
// åœ¨å‰ç«¯ç»„ä»¶ä¸­ä½¿ç”¨æµå¼è¾“å‡º
const handleGenerateDiagram = async (description: string) => {
  const agent = getSelectedAgent();
  
  await agent.generateDiagram(
    { description },
    (chunk: string) => {
      // å®æ—¶æ›´æ–°UIæ˜¾ç¤º
      setStreamingContent(prev => prev + chunk);
    }
  );
};
```

## ğŸ“± ç”¨æˆ·ä½“éªŒ

### æ”¯æŒæµå¼çš„æ¨¡å‹

- âš¡ **å®æ—¶å“åº”**: ç”¨æˆ·å¯ä»¥çœ‹åˆ°AIé€å­—ç”Ÿæˆå†…å®¹
- ğŸ¯ **å³æ—¶åé¦ˆ**: æ›´å¿«çš„æ„ŸçŸ¥å“åº”é€Ÿåº¦
- ğŸ”„ **æµç•…ä½“éªŒ**: å‡å°‘ç­‰å¾…æ—¶é—´çš„ç„¦è™‘æ„Ÿ

### ä¸æ”¯æŒæµå¼çš„æ¨¡å‹

- â³ **ç­‰å¾…æ¨¡å¼**: æ˜¾ç¤ºåŠ è½½çŠ¶æ€ç›´åˆ°å®Œæ•´å“åº”
- ğŸ”„ **è‡ªåŠ¨é™çº§**: æ— éœ€ç”¨æˆ·å¹²é¢„ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°æ™®é€šæ¨¡å¼
- âœ… **åŠŸèƒ½å®Œæ•´**: æ‰€æœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼Œåªæ˜¯å“åº”æ–¹å¼ä¸åŒ

## ğŸ”§ å¼€å‘æŒ‡å—

### ç«å±±å¼•æ“æµå¼è¾“å‡ºå®ç°

ç«å±±å¼•æ“ API åŸç”Ÿæ”¯æŒæµå¼è¾“å‡ºï¼Œä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š

```bash
# ç«å±±å¼•æ“æµå¼è¯·æ±‚ç¤ºä¾‹
curl https://ark.cn-beijing.volces.com/api/v3/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $ARK_API_KEY" \
  -d '{
    "model": "ep-20250617131345-rshkp",
    "messages": [
        {
            "role": "user",
            "content": "åˆ›å»ºä¸€ä¸ªç™»å½•æµç¨‹å›¾"
        }
    ],
    "stream": true
  }'
```

### Qwen é€šä¹‰åƒé—®æµå¼è¾“å‡ºå®ç°

Qwen API å®Œå…¨å…¼å®¹ OpenAI æ ¼å¼ï¼ŒåŸç”Ÿæ”¯æŒæµå¼è¾“å‡ºï¼š

```bash
# Qwen æµå¼è¯·æ±‚ç¤ºä¾‹
curl https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $DASHSCOPE_API_KEY" \
  -d '{
    "model": "qwen-plus",
    "messages": [
        {
            "role": "user",
            "content": "åˆ›å»ºä¸€ä¸ªç™»å½•æµç¨‹å›¾"
        }
    ],
    "stream": true
  }'
```

```javascript
// JavaScript å®ç°ç¤ºä¾‹
import OpenAI from "openai";

const openai = new OpenAI({
    apiKey: process.env.DASHSCOPE_API_KEY,
    baseURL: "https://dashscope.aliyuncs.com/compatible-mode/v1"
});

async function streamQwen() {
    const completion = await openai.chat.completions.create({
        model: "qwen-plus",
        messages: [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "åˆ›å»ºä¸€ä¸ªç™»å½•æµç¨‹å›¾"}
        ],
        stream: true,
    });
    
    for await (const chunk of completion) {
        console.log(chunk.choices[0]?.delta?.content || '');
    }
}
```

### æ·»åŠ æ–°çš„æµå¼æ”¯æŒ

å¦‚æœè¦ä¸ºè‡ªå®šä¹‰æä¾›å•†æ·»åŠ æµå¼æ”¯æŒï¼Œéœ€è¦ï¼š

1. **å®ç°æµå¼æ–¹æ³•**:

```typescript
export class VolcengineLangChainProvider extends BaseChatModel {
  async *_streamResponseChunks(
    messages: BaseMessage[],
    options: BaseChatModelCallOptions,
    runManager?: CallbackManagerForLLMRun
  ): AsyncGenerator<ChatGenerationChunk> {
    // ç«å±±å¼•æ“æµå¼å“åº”é€»è¾‘
    const response = await fetch('https://ark.cn-beijing.volces.com/api/v3/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`,
        'Accept': 'text/event-stream'
      },
      body: JSON.stringify({
        model: this.modelName,
        messages: messages.map(m => ({ role: m._getType(), content: m.content })),
        stream: true,  // å¯ç”¨æµå¼è¾“å‡º
        temperature: this.temperature,
        max_tokens: this.maxTokens
      })
    });
    
    const reader = response.body?.getReader();
    const decoder = new TextDecoder();
    
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      
      const chunk = decoder.decode(value);
      const lines = chunk.split('\n').filter(line => line.trim());
      
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6);
          if (data === '[DONE]') return;
          
          try {
            const parsed = JSON.parse(data);
            const content = parsed.choices?.[0]?.delta?.content;
            if (content) {
              yield new ChatGenerationChunk({
                message: new AIMessage(content),
                text: content
              });
            }
          } catch (e) {
            // å¿½ç•¥è§£æé”™è¯¯
          }
        }
      }
    }
  }
}
```

2. **æ›´æ–°æ”¯æŒæ£€æµ‹**:

```typescript
private supportsStreaming(): boolean {
  const modelType = this.model._llmType();
  return modelType === 'openai' || 
         modelType === 'anthropic' || 
         modelType === 'volcengine';  // ç«å±±å¼•æ“æ”¯æŒæµå¼
}
```

### æµ‹è¯•æµå¼åŠŸèƒ½

```typescript
// æµ‹è¯•æµå¼è¾“å‡º
const testStreaming = async () => {
  const agent = DiagramAgentFactory.createOpenAIAgent({
    apiKey: 'your-api-key'
  });
  
  let streamedContent = '';
  
  await agent.generateDiagram(
    { description: 'åˆ›å»ºä¸€ä¸ªç®€å•çš„æµç¨‹å›¾' },
    (chunk) => {
      streamedContent += chunk;
      console.log('æ”¶åˆ°æµå¼æ•°æ®:', chunk);
    }
  );
  
  console.log('å®Œæ•´å†…å®¹:', streamedContent);
};
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æµå¼è¾“å‡ºä¸­æ–­**
   - æ£€æŸ¥ç½‘ç»œè¿æ¥ç¨³å®šæ€§
   - ç¡®è®¤APIå¯†é’¥æœ‰æ•ˆæ€§
   - æŸ¥çœ‹æ§åˆ¶å°é”™è¯¯ä¿¡æ¯

2. **ä¸æ”¯æŒæµå¼çš„æ¨¡å‹æ˜¾ç¤ºå¼‚å¸¸**
   - ç³»ç»Ÿä¼šè‡ªåŠ¨é™çº§ï¼Œæ— éœ€æ‰‹åŠ¨å¤„ç†
   - æ£€æŸ¥ `supportsStreaming()` æ–¹æ³•è¿”å›å€¼

3. **æµå¼æ•°æ®æ ¼å¼é”™è¯¯**
   - ç¡®è®¤æä¾›å•†APIè¿”å›æ ¼å¼
   - æ£€æŸ¥æ•°æ®è§£æé€»è¾‘

### è°ƒè¯•æŠ€å·§

```typescript
// å¯ç”¨è¯¦ç»†æ—¥å¿—
console.log('DiagramAgent: æµå¼è¾“å‡º:', onStream ? 'å¯ç”¨' : 'ç¦ç”¨');
console.log('DiagramAgent: æ¨¡å‹ç±»å‹:', this.model._llmType());
console.log('DiagramAgent: æ”¯æŒæµå¼:', this.supportsStreaming());
```

## ğŸ”® æœªæ¥è®¡åˆ’

### çŸ­æœŸç›®æ ‡

- [ ] ä¸ºç«å±±å¼•æ“è±†åŒ…æ·»åŠ æµå¼æ”¯æŒ
- [ ] ä¸º Qwen é€šä¹‰åƒé—®æ·»åŠ æµå¼æ”¯æŒ
- [ ] ä¼˜åŒ–æµå¼æ•°æ®çš„è§£æå’Œæ˜¾ç¤º
- [ ] åœ¨ LangChain é€‚é…å™¨ä¸­å®ç°æµå¼æ”¯æŒ

### é•¿æœŸç›®æ ‡

- [ ] æ”¯æŒæ›´å¤šAIæä¾›å•†çš„æµå¼è¾“å‡º
- [ ] å®ç°æµå¼è¾“å‡ºçš„æš‚åœ/æ¢å¤åŠŸèƒ½
- [ ] æ·»åŠ æµå¼è¾“å‡ºçš„æ€§èƒ½ç›‘æ§

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœåœ¨ä½¿ç”¨æµå¼è¾“å‡ºåŠŸèƒ½æ—¶é‡åˆ°é—®é¢˜ï¼š

1. æŸ¥çœ‹æµè§ˆå™¨æ§åˆ¶å°çš„é”™è¯¯ä¿¡æ¯
2. ç¡®è®¤ä½¿ç”¨çš„æ˜¯æ”¯æŒæµå¼çš„æ¨¡å‹ï¼ˆOpenAI/Claudeï¼‰
3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®
4. éªŒè¯APIå¯†é’¥çš„æœ‰æ•ˆæ€§å’Œæƒé™
5. æäº¤ [GitHub Issue](https://github.com/echoVic/flow-ai/issues) å¯»æ±‚å¸®åŠ©

---

**æ³¨æ„**: æµå¼è¾“å‡ºåŠŸèƒ½éœ€è¦ç¨³å®šçš„ç½‘ç»œè¿æ¥ã€‚åœ¨ç½‘ç»œä¸ç¨³å®šçš„ç¯å¢ƒä¸‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é™çº§åˆ°æ™®é€šè°ƒç”¨æ¨¡å¼ã€‚
