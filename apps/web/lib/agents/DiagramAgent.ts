/**
 * åŸºäº LangChain çš„å›¾è¡¨ç”Ÿæˆ Agent
 * åˆ©ç”¨ LangChain çš„èƒ½åŠ›å®ç°å¯å¤ç”¨çš„ AI å›¾è¡¨ç”Ÿæˆ
 */
import { ChatAnthropic } from "@langchain/anthropic";
import { CallbackManagerForLLMRun } from "@langchain/core/callbacks/manager";
import { BaseChatModel, BaseChatModelCallOptions } from "@langchain/core/language_models/chat_models";
import { AIMessage, AIMessageChunk, BaseMessage, HumanMessage, SystemMessage } from "@langchain/core/messages";
import { ChatGenerationChunk, ChatResult } from "@langchain/core/outputs";
import { ChatOpenAI } from "@langchain/openai";
import { z } from "zod";

// å›¾è¡¨ç”Ÿæˆè¯·æ±‚æ¥å£
export interface DiagramGenerationRequest {
  description: string;
  diagramType?: 'flowchart' | 'sequence' | 'class' | 'state' | 'er' | 'journey' | 'gantt' | 'pie' | 'quadrant' | 'mindmap' | 'gitgraph' | 'kanban' | 'architecture' | 'packet';
  existingCode?: string;
  optimizationRequirements?: string;
}

// å›¾è¡¨ç”Ÿæˆç»“æœæ¥å£
export interface DiagramGenerationResult {
  mermaidCode: string;
  explanation: string;
  suggestions: string[];
  diagramType: string;
  metadata: {
    model: string;
    provider: string;
    usage?: {
      totalTokens?: number;
      promptTokens?: number;
      completionTokens?: number;
    };
  };
}

// Agent é…ç½®æ¥å£
export interface DiagramAgentConfig {
  model: BaseChatModel;
  temperature?: number;
  maxTokens?: number;
  retryCount?: number;
  enableMemory?: boolean;
}

// Qwen Provider é€‚é…å™¨
export class QwenLangChainProvider extends BaseChatModel {
  private apiKey: string;
  private endpoint: string;
  private modelName: string;
  private temperature: number;
  private maxTokens: number;

  constructor(config: {
    apiKey: string;
    endpoint?: string;
    modelName?: string;
    temperature?: number;
    maxTokens?: number;
  }) {
    super({});
    
    this.apiKey = config.apiKey;
    this.endpoint = config.endpoint || 'https://dashscope.aliyuncs.com/compatible-mode/v1';
    this.modelName = config.modelName || 'qwen-max';
    this.temperature = config.temperature || 0.7;
    this.maxTokens = config.maxTokens || 2048;
  }

  async _generate(
    messages: BaseMessage[],
    options: BaseChatModelCallOptions,
    runManager?: CallbackManagerForLLMRun
  ): Promise<ChatResult> {
    try {
      console.log('Volcengine API Configuration:', {
        endpoint: this.endpoint,
        modelName: this.modelName,
        hasApiKey: !!this.apiKey,
        hasValidModel: this.modelName.startsWith('ep-') || this.modelName.includes('doubao') || this.modelName.includes('deepseek')
      });
      
      // éªŒè¯æ¨¡å‹åç§°æ ¼å¼
      if (!this.modelName.startsWith('ep-') && !this.modelName.includes('doubao') && !this.modelName.includes('deepseek')) {
        console.warn('æ¨¡å‹åç§°å¯èƒ½ä¸æ­£ç¡®ï¼Œç«å±±å¼•æ“æ¨¡å‹é€šå¸¸ä»¥ ep- å¼€å¤´ï¼Œä¾‹å¦‚: ep-20250617131345-rshkp');
      }
      
      const openaiMessages = messages.map(msg => ({
        role: msg._getType() === 'system' ? 'system' : 
              msg._getType() === 'human' ? 'user' : 'assistant',
        content: msg.content as string
      }));

      const response = await fetch(`${this.endpoint}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.modelName,
          messages: openaiMessages,
          temperature: (options as any).temperature || this.temperature,
          max_tokens: (options as any).maxTokens || this.maxTokens,
        }),
      });

      if (!response.ok) {
        throw new Error(`Qwen API error: ${response.status}`);
      }

      const result = await response.json();
      const content = result.choices[0].message.content;

      return {
        generations: [
          {
            text: content,
            message: new AIMessage(content)
          }
        ]
      };
    } catch (error: any) {
      throw new Error(`Qwen provider error: ${error.message}`);
    }
  }

  _llmType(): string {
    return 'qwen';
  }

  // æ·»åŠ æµå¼æ”¯æŒ
  async *_streamResponseChunks(
    messages: BaseMessage[],
    options: BaseChatModelCallOptions,
    runManager?: CallbackManagerForLLMRun
  ): AsyncGenerator<ChatGenerationChunk> {
    try {
      console.log('Volcengine API Configuration:', {
        endpoint: this.endpoint,
        modelName: this.modelName,
        hasApiKey: !!this.apiKey,
        hasValidModel: this.modelName.startsWith('ep-') || this.modelName.includes('doubao') || this.modelName.includes('deepseek')
      });
      
      // éªŒè¯æ¨¡å‹åç§°æ ¼å¼
      if (!this.modelName.startsWith('ep-') && !this.modelName.includes('doubao') && !this.modelName.includes('deepseek')) {
        console.warn('æ¨¡å‹åç§°å¯èƒ½ä¸æ­£ç¡®ï¼Œç«å±±å¼•æ“æ¨¡å‹é€šå¸¸ä»¥ ep- å¼€å¤´ï¼Œä¾‹å¦‚: ep-20250617131345-rshkp');
      }
      
      const openaiMessages = messages.map(msg => ({
        role: msg._getType() === 'system' ? 'system' : 
              msg._getType() === 'human' ? 'user' : 'assistant',
        content: msg.content as string
      }));

      const response = await fetch(`${this.endpoint}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.modelName,
          messages: openaiMessages,
          temperature: (options as any).temperature || this.temperature,
          max_tokens: (options as any).maxTokens || this.maxTokens,
          stream: true, // å¯ç”¨æµå¼è¾“å‡º
        }),
      });

      if (!response.ok) {
        throw new Error(`Qwen API error: ${response.status}`);
      }

      const reader = response.body?.getReader();
      if (!reader) {
        throw new Error('æ— æ³•è·å–å“åº”æµ');
      }

      const decoder = new TextDecoder();
      
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        const lines = chunk.split('\n').filter(line => line.trim());
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            if (data === '[DONE]') return;
            
            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              if (content) {
                yield new ChatGenerationChunk({
                  text: content,
                  message: new AIMessageChunk({ content }),
                  generationInfo: {}
                });
              }
            } catch (e) {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
        }
      }
    } catch (error: any) {
      throw new Error(`Qwen streaming error: ${error.message}`);
    }
  }
}

// Volcengine Provider é€‚é…å™¨
export class VolcengineLangChainProvider extends BaseChatModel {
  private apiKey: string;
  private endpoint: string;
  private modelName: string;
  private temperature: number;
  private maxTokens: number;

  constructor(config: {
    apiKey: string;
    endpoint?: string;
    modelName?: string;
    temperature?: number;
    maxTokens?: number;
  }) {
    super({});
    
    this.apiKey = config.apiKey;
    this.endpoint = config.endpoint || process.env.NEXT_PUBLIC_ARK_ENDPOINT || 'https://ark.cn-beijing.volces.com/api/v3';
    this.modelName = config.modelName || process.env.NEXT_PUBLIC_ARK_MODEL_NAME || 'ep-20250617131345-rshkp';
    this.temperature = config.temperature || 0.7;
    this.maxTokens = config.maxTokens || 2048;
    
    if (!this.apiKey) {
      throw new Error('Volcengine API key is required');
    }
    if (!this.modelName) {
      throw new Error('Volcengine model name is required');
    }
    
    // ç¡®ä¿ endpoint ä»¥ /v3 ç»“å°¾ï¼Œç”¨äºç«å±±å¼•æ“ API
    if (!this.endpoint.endsWith('/v3') && !this.endpoint.endsWith('/v3/')) {
      this.endpoint = this.endpoint.replace(/\/?$/, '/v3');
    }
  }

  async _generate(
    messages: BaseMessage[],
    options: BaseChatModelCallOptions,
    runManager?: CallbackManagerForLLMRun
  ): Promise<ChatResult> {
    try {
      const openaiMessages = messages.map(msg => ({
        role: msg._getType() === 'system' ? 'system' : 
              msg._getType() === 'human' ? 'user' : 'assistant',
        content: msg.content as string
      }));

      const response = await fetch(`${this.endpoint}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.modelName,
          messages: openaiMessages,
          temperature: (options as any).temperature || this.temperature,
          max_tokens: (options as any).maxTokens || this.maxTokens,
        }),
      });

      if (!response.ok) {
        const errorText = await response.text().catch(() => 'No error details available');
        let errorMessage = `Volcengine API error: ${response.status}`;
        
        if (response.status === 404) {
          errorMessage += ' - Model not found or endpoint incorrect. Please check your model name and endpoint configuration.';
        } else if (response.status === 401) {
          errorMessage += ' - Authentication failed. Please check your API key.';
        } else if (response.status === 400) {
          errorMessage += ' - Bad request. Please check your request parameters.';
        }
        
        if (errorText) {
          errorMessage += ` Details: ${errorText}`;
        }
        
        throw new Error(errorMessage);
      }

      const result = await response.json();
      const content = result.choices[0].message.content;

      return {
        generations: [
          {
            text: content,
            message: new AIMessage(content)
          }
        ]
      };
    } catch (error: any) {
      throw new Error(`Volcengine provider error: ${error.message}`);
    }
  }

  _llmType(): string {
    return 'volcengine';
  }

  // æ·»åŠ æµå¼æ”¯æŒ
  async *_streamResponseChunks(
    messages: BaseMessage[],
    options: BaseChatModelCallOptions,
    runManager?: CallbackManagerForLLMRun
  ): AsyncGenerator<ChatGenerationChunk> {
    try {
      const openaiMessages = messages.map(msg => ({
        role: msg._getType() === 'system' ? 'system' : 
              msg._getType() === 'human' ? 'user' : 'assistant',
        content: msg.content as string
      }));

      const response = await fetch(`${this.endpoint}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.modelName,
          messages: openaiMessages,
          temperature: (options as any).temperature || this.temperature,
          max_tokens: (options as any).maxTokens || this.maxTokens,
          stream: true, // å¯ç”¨æµå¼è¾“å‡º
        }),
      });

      if (!response.ok) {
        const errorText = await response.text().catch(() => 'No error details available');
        let errorMessage = `Volcengine API error: ${response.status}`;
        
        if (response.status === 404) {
          errorMessage += ' - Model not found or endpoint incorrect. Please check your model name and endpoint configuration.';
        } else if (response.status === 401) {
          errorMessage += ' - Authentication failed. Please check your API key.';
        } else if (response.status === 400) {
          errorMessage += ' - Bad request. Please check your request parameters.';
        }
        
        if (errorText) {
          errorMessage += ` Details: ${errorText}`;
        }
        
        throw new Error(errorMessage);
      }

      const reader = response.body?.getReader();
      if (!reader) {
        throw new Error('æ— æ³•è·å–å“åº”æµ');
      }

      const decoder = new TextDecoder();
      
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        const lines = chunk.split('\n').filter(line => line.trim());
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            if (data === '[DONE]') return;
            
            try {
              const parsed = JSON.parse(data);
              const content = parsed.choices?.[0]?.delta?.content;
              if (content) {
                yield new ChatGenerationChunk({
                  text: content,
                  message: new AIMessageChunk({ content }),
                  generationInfo: {}
                });
              }
            } catch (e) {
              // å¿½ç•¥è§£æé”™è¯¯
            }
          }
        }
      }
    } catch (error: any) {
      throw new Error(`Volcengine streaming error: ${error.message}`);
    }
  }
}

/**
 * åŸºäº LangChain çš„å›¾è¡¨ç”Ÿæˆ Agent
 */
export class DiagramAgent {
  private model: BaseChatModel;
  private config: DiagramAgentConfig;
  private conversationHistory: BaseMessage[] = [];

  constructor(config: DiagramAgentConfig) {
    this.config = config;
    this.model = config.model;
    
    // åˆå§‹åŒ–ç³»ç»Ÿæç¤º
    this.initializeSystemPrompt();
  }

  /**
   * ç”Ÿæˆå›¾è¡¨ (æ”¯æŒæµå¼è¾“å‡º)
   */
  async generateDiagram(
    request: DiagramGenerationRequest, 
    onStream?: (chunk: string) => void
  ): Promise<DiagramGenerationResult> {
    try {
      console.log('DiagramAgent: å¼€å§‹ç”Ÿæˆå›¾è¡¨');
      console.log('- æè¿°:', request.description);
      console.log('- å›¾è¡¨ç±»å‹:', request.diagramType);
      console.log('- ç°æœ‰ä»£ç :', request.existingCode ? 'å­˜åœ¨' : 'ä¸å­˜åœ¨');
      console.log('- æµå¼è¾“å‡º:', onStream ? 'å¯ç”¨' : 'ç¦ç”¨');

      // æ„å»ºæç¤ºæ¶ˆæ¯
      const userPrompt = this.buildGenerationPrompt(request);
      const messages = this.buildMessages(userPrompt);

      // è°ƒç”¨ AI æ¨¡å‹
      const response = await this.invokeModel(messages, onStream);
      
      // è§£æå“åº”
      const result = this.parseResponse(response, request);
      
      // æ›´æ–°å¯¹è¯å†å²
      if (this.config.enableMemory) {
        console.log('DiagramAgent: æ›´æ–°å¯¹è¯å†å²');
        this.updateConversationHistory(userPrompt, response);
        console.log('DiagramAgent: å½“å‰å¯¹è¯å†å²é•¿åº¦:', this.conversationHistory.length);
      }

      console.log('DiagramAgent: å›¾è¡¨ç”Ÿæˆå®Œæˆ');
      return result;

    } catch (error: any) {
      console.error('DiagramAgent: å›¾è¡¨ç”Ÿæˆå¤±è´¥', error);
      throw new Error(`å›¾è¡¨ç”Ÿæˆå¤±è´¥: ${error.message}`);
    }
  }

  /**
   * ä¼˜åŒ–å›¾è¡¨
   */
  async optimizeDiagram(mermaidCode: string, requirements: string): Promise<DiagramGenerationResult> {
    const request: DiagramGenerationRequest = {
      description: requirements,
      existingCode: mermaidCode,
      optimizationRequirements: requirements
    };

    return this.generateDiagram(request);
  }

  /**
   * æ‰¹é‡ç”Ÿæˆå›¾è¡¨
   */
  async batchGenerateDiagrams(requests: DiagramGenerationRequest[]): Promise<DiagramGenerationResult[]> {
    const results = await Promise.all(
      requests.map(request => this.generateDiagram(request))
    );
    return results;
  }

  /**
   * æ¸…ç©ºå¯¹è¯å†å²
   */
  clearHistory(): void {
    this.conversationHistory = [];
    this.initializeSystemPrompt();
  }

  /**
   * è®¾ç½®å¯¹è¯å†å²
   */
  setConversationHistory(history: Array<{role: string, content: string}>): void {
    this.conversationHistory = [new SystemMessage(this.getSystemPrompt())];
    
    for (const msg of history) {
      if (msg.role === 'user') {
        this.conversationHistory.push(new HumanMessage(msg.content));
      } else if (msg.role === 'assistant') {
        this.conversationHistory.push(new AIMessage(msg.content));
      }
    }
    
    console.log('DiagramAgent: è®¾ç½®å¯¹è¯å†å²å®Œæˆï¼Œå…±', this.conversationHistory.length - 1, 'æ¡æ¶ˆæ¯');
  }

  /**
   * è·å–å¯¹è¯å†å²
   */
  getConversationHistory(): Array<{role: string, content: string}> {
    return this.conversationHistory
      .filter(msg => msg._getType() !== 'system') // æ’é™¤ç³»ç»Ÿæ¶ˆæ¯
      .map(msg => ({
        role: msg._getType() === 'human' ? 'user' : 'assistant',
        content: msg.content as string
      }));
  }

  /**
   * è·å–ç³»ç»Ÿæç¤º
   */
  private getSystemPrompt(): string {
    return `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¶æ„å›¾ç”Ÿæˆä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„æè¿°ç”Ÿæˆé«˜è´¨é‡çš„Mermaidä»£ç ã€‚

ğŸ”¥ å…³é”®è§„åˆ™ - å¿…é¡»ä¸¥æ ¼éµå®ˆï¼š
1. ä¸¥æ ¼æŒ‰ç…§Mermaidè¯­æ³•è§„èŒƒç”Ÿæˆä»£ç 
2. æ ¹æ®æè¿°é€‰æ‹©æœ€åˆé€‚çš„å›¾è¡¨ç±»å‹
3. èŠ‚ç‚¹å‘½åè¦æ¸…æ™°ã€æœ‰æ„ä¹‰ï¼Œç»å¯¹ä¸èƒ½ä½¿ç”¨ä¿ç•™å…³é”®å­—
4. è¿æ¥å…³ç³»è¦ç¬¦åˆé€»è¾‘
5. ä»£ç ç»“æ„è¦æ¸…æ™°æ˜“è¯»

ğŸš« ç»å¯¹ç¦æ­¢ä½¿ç”¨çš„ä¿ç•™å…³é”®å­—ä½œä¸ºèŠ‚ç‚¹IDï¼š
end, start, stop, class, state, note, loop, alt, opt, par, critical, break, rect, activate, deactivate, if, else, elseif, endif

âœ… æ­£ç¡®çš„èŠ‚ç‚¹IDå‘½åè§„èŒƒï¼š
- ä½¿ç”¨æè¿°æ€§åç§°ï¼šstartNode, endNode, processStep, checkPoint, resultNode
- å­—æ¯å¼€å¤´ï¼Œå¯åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿
- é¿å…å•ä¸ªè¯æ±‡ï¼Œä½¿ç”¨ç»„åˆè¯ï¼šloginProcess, dataValidation, userRegistration
- ä¸­æ–‡æ ‡ç­¾æ”¾åœ¨æ–¹æ‹¬å·å†…ï¼šstartNode[å¼€å§‹], endNode([ç»“æŸ])

âœ… æ­£ç¡®çš„è¯­æ³•æ ¼å¼ï¼š
- ç®­å¤´å‰åè¦æœ‰ç©ºæ ¼ï¼šnodeA --> nodeB
- æ¯è¡Œä»£ç ç»“å°¾ä¸è¦æœ‰å¤šä½™ç©ºæ ¼
- ç¡®ä¿æ‰€æœ‰èŠ‚ç‚¹IDåœ¨æ•´ä¸ªå›¾è¡¨ä¸­å”¯ä¸€

ğŸ“ æ ‡å‡†æ¨¡æ¿ç¤ºä¾‹ï¼š
\`\`\`
flowchart TD
    startNode([å¼€å§‹]) --> inputData[è¾“å…¥æ•°æ®]
    inputData --> processData[å¤„ç†æ•°æ®]
    processData --> checkResult{æ£€æŸ¥ç»“æœ}
    checkResult -->|æˆåŠŸ| outputResult[è¾“å‡ºç»“æœ]
    checkResult -->|å¤±è´¥| errorHandle[é”™è¯¯å¤„ç†]
    outputResult --> endNode([ç»“æŸ])
    errorHandle --> endNode
\`\`\`

âš ï¸ ç‰¹åˆ«æ³¨æ„ï¼š
- ç»å¯¹ä¸è¦ä½¿ç”¨ "end" ä½œä¸ºèŠ‚ç‚¹IDï¼Œå¿…é¡»ä½¿ç”¨ "endNode" æˆ– "finishNode"
- ç»å¯¹ä¸è¦ä½¿ç”¨ "start" ä½œä¸ºèŠ‚ç‚¹IDï¼Œå¿…é¡»ä½¿ç”¨ "startNode" æˆ– "beginNode"
- ç»å¯¹ä¸è¦ä½¿ç”¨ "class" ä½œä¸ºèŠ‚ç‚¹IDï¼Œå¿…é¡»ä½¿ç”¨ "classNode" æˆ– "classInfo"
- ç»å¯¹ä¸è¦ä½¿ç”¨ "state" ä½œä¸ºèŠ‚ç‚¹IDï¼Œå¿…é¡»ä½¿ç”¨ "stateNode" æˆ– "statusNode"

æ”¯æŒçš„å›¾è¡¨ç±»å‹ï¼š
- flowchart: æµç¨‹å›¾ (æ¨èç”¨äºä¸šåŠ¡æµç¨‹ã€ç³»ç»Ÿæ¶æ„)
- sequence: æ—¶åºå›¾ (æ¨èç”¨äºäº¤äº’æµç¨‹ã€APIè°ƒç”¨)
- class: ç±»å›¾ (æ¨èç”¨äºç³»ç»Ÿè®¾è®¡ã€æ•°æ®ç»“æ„)
- state: çŠ¶æ€å›¾ (æ¨èç”¨äºå¯¹è±¡ç”Ÿå‘½å‘¨æœŸã€åè®®çŠ¶æ€æœº)
- er: å®ä½“å…³ç³»å›¾ (æ¨èç”¨äºæ•°æ®åº“è®¾è®¡)
- journey: ç”¨æˆ·æ—…ç¨‹å›¾ (æ¨èç”¨äºç”¨æˆ·ä½“éªŒè®¾è®¡)
- gantt: ç”˜ç‰¹å›¾ (æ¨èç”¨äºé¡¹ç›®è®¡åˆ’ã€æ—¶é—´å®‰æ’)
- pie: é¥¼å›¾ (æ¨èç”¨äºæ•°æ®ç»Ÿè®¡ã€æ¯”ä¾‹å±•ç¤º)
- quadrant: å››è±¡é™å›¾ (æ¨èç”¨äºæˆ˜ç•¥åˆ†æã€ä¼˜å…ˆçº§æ’åº)
- mindmap: æ€ç»´å¯¼å›¾ (æ¨èç”¨äºå¤´è„‘é£æš´ã€çŸ¥è¯†æ•´ç†)
- gitgraph: Gitåˆ†æ”¯å›¾ (æ¨èç”¨äºç‰ˆæœ¬ç®¡ç†æµç¨‹)
- kanban: çœ‹æ¿å›¾ (æ¨èç”¨äºä»»åŠ¡ç®¡ç†ã€æ•æ·å¼€å‘)
- architecture: æ¶æ„å›¾ (C4é£æ ¼ï¼Œæ¨èç”¨äºå¤æ‚ç³»ç»Ÿæ¶æ„å±•ç¤º)
- packet: æ•°æ®åŒ…å›¾ (æ¨èç”¨äºç½‘ç»œåè®®åˆ†æ)

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
{\n  "mermaidCode": "è¿™é‡Œæ˜¯ç”Ÿæˆçš„mermaidä»£ç ",\n  "explanation": "ç®€è¦è¯´æ˜ä»£ç çš„åŠŸèƒ½å’Œç»“æ„",\n  "suggestions": ["ä¼˜åŒ–å»ºè®®1", "ä¼˜åŒ–å»ºè®®2"],\n  "diagramType": "å›¾è¡¨ç±»å‹"\n}`;
  }

  /**
   * åˆå§‹åŒ–ç³»ç»Ÿæç¤º
   */
  private initializeSystemPrompt(): void {
    this.conversationHistory = [new SystemMessage(this.getSystemPrompt())];
  }

  /**
   * æ„å»ºç”Ÿæˆæç¤º
   */
  private buildGenerationPrompt(request: DiagramGenerationRequest): string {
    if (request.existingCode && request.optimizationRequirements) {
      return `è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ä¼˜åŒ–æ¶æ„å›¾ï¼š

å½“å‰Mermaidä»£ç ï¼š
\`\`\`mermaid
${request.existingCode}
\`\`\`

ä¼˜åŒ–è¦æ±‚ï¼š${request.optimizationRequirements}

è¯·ä¿æŒåŸæœ‰ç»“æ„çš„åŸºç¡€ä¸Šï¼Œæ ¹æ®è¦æ±‚è¿›è¡Œä¼˜åŒ–æ”¹è¿›ã€‚`;
    }

    if (request.existingCode) {
      return `è¯·åŸºäºç°æœ‰ä»£ç è¿›è¡Œä¼˜åŒ–å’Œæ‰©å±•ï¼š

ç°æœ‰ä»£ç ï¼š
\`\`\`mermaid
${request.existingCode}
\`\`\`

æ–°éœ€æ±‚ï¼š${request.description}
å»ºè®®å›¾è¡¨ç±»å‹ï¼š${request.diagramType || 'è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„ç±»å‹'}

è¯·ä¿æŒåŸæœ‰ç»“æ„çš„åŸºç¡€ä¸Šï¼Œæ ¹æ®æ–°éœ€æ±‚è¿›è¡Œä¼˜åŒ–ã€‚`;
    }

    return `è¯·æ ¹æ®ä»¥ä¸‹æè¿°ç”Ÿæˆæ¶æ„å›¾ï¼š

éœ€æ±‚æè¿°ï¼š${request.description}
å»ºè®®å›¾è¡¨ç±»å‹ï¼š${request.diagramType || 'è¯·è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„å›¾è¡¨ç±»å‹'}

è¯·ç”Ÿæˆæ¸…æ™°ã€ä¸“ä¸šçš„æ¶æ„å›¾ä»£ç ã€‚`;
  }

  /**
   * æ„å»ºæ¶ˆæ¯åˆ—è¡¨
   */
  private buildMessages(userPrompt: string): BaseMessage[] {
    // åˆ›å»ºä¸´æ—¶æ¶ˆæ¯æ•°ç»„ï¼Œä¸ä¿®æ”¹conversationHistory
    const messages = [...this.conversationHistory];
    messages.push(new HumanMessage(userPrompt));
    return messages;
  }

  /**
   * è°ƒç”¨ AI æ¨¡å‹ (æ”¯æŒæµå¼è¾“å‡º)
   */
  private async invokeModel(messages: BaseMessage[], onStream?: (chunk: string) => void): Promise<string> {
    const retryCount = this.config.retryCount || 3;
    
    for (let i = 0; i < retryCount; i++) {
      try {
        // å¦‚æœæ”¯æŒæµå¼è¾“å‡ºä¸”æä¾›äº†å›è°ƒå‡½æ•°
        if (onStream && this.supportsStreaming()) {
          return await this.invokeModelStream(messages, onStream);
        }
        
        // éæµå¼è°ƒç”¨
        const response = await this.model.invoke(messages);
        return response.content as string;
        
      } catch (error: any) {
        console.warn(`DiagramAgent: è°ƒç”¨å¤±è´¥ï¼Œé‡è¯• ${i + 1}/${retryCount}`, error.message);
        await this.sleep(1000 * (i + 1));
      }
    }
    
    throw new Error('AI æ¨¡å‹è°ƒç”¨å¤±è´¥');
  }

  /**
   * æµå¼è°ƒç”¨ AI æ¨¡å‹
   */
  private async invokeModelStream(messages: BaseMessage[], onStream: (chunk: string) => void): Promise<string> {
    let fullContent = '';
    
    try {
      const stream = await this.model.stream(messages);
      
      for await (const chunk of stream) {
        const content = chunk.content as string;
        if (content) {
          fullContent += content;
          onStream(content);
        }
      }
      
      return fullContent;
    } catch (error: any) {
      console.error('DiagramAgent: æµå¼è°ƒç”¨å¤±è´¥', error);
      // é™çº§åˆ°éæµå¼è°ƒç”¨
      const response = await this.model.invoke(messages);
      return response.content as string;
    }
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒæµå¼è¾“å‡º
   */
  public supportsStreaming(): boolean {
    const modelType = this.model._llmType();
    // OpenAIã€Anthropicã€ç«å±±å¼•æ“ã€Qwen éƒ½æ”¯æŒæµå¼è¾“å‡º
    return modelType === 'openai' || 
           modelType === 'anthropic' || 
           modelType === 'volcengine' || 
           modelType === 'qwen';
  }

  /**
   * é¢„å¤„ç†å’Œä¿®å¤ Mermaid ä»£ç ä¸­çš„å¸¸è§é—®é¢˜
   */
  private preprocessMermaidCode(code: string): string {
    console.log('DiagramAgent: å¼€å§‹é¢„å¤„ç† Mermaid ä»£ç ');
    
    // å®šä¹‰ä¿ç•™å…³é”®å­—æ˜ å°„ - æ‰©å±•ç‰ˆæœ¬
    const reservedKeywords = {
      'end': 'endNode',
      'start': 'startNode', 
      'stop': 'stopNode',
      'class': 'classNode',
      'state': 'stateNode',
      'note': 'noteNode',
      'loop': 'loopNode',
      'alt': 'altNode',
      'opt': 'optNode',
      'par': 'parNode',
      'critical': 'criticalNode',
      'break': 'breakNode',
      'rect': 'rectNode',
      'activate': 'activateNode',
      'deactivate': 'deactivateNode',
      'if': 'ifNode',
      'else': 'elseNode',
      'elseif': 'elseifNode',
      'endif': 'endifNode',
      // æ·»åŠ æ›´å¤šå¯èƒ½çš„ä¿ç•™å…³é”®å­—
      'and': 'andNode',
      'or': 'orNode',
      'not': 'notNode',
      'true': 'trueNode',
      'false': 'falseNode'
    };
    
    let processedCode = code.trim();
    let hasChanges = false;
    
    // æŒ‰è¡Œå¤„ç†ä»£ç 
    const lines = processedCode.split('\n');
    const processedLines = lines.map((line, index) => {
      let processedLine = line.trim();
      
      // è·³è¿‡ç©ºè¡Œã€æ³¨é‡Šå’Œå›¾è¡¨ç±»å‹å£°æ˜è¡Œ
      if (!processedLine || 
          processedLine.startsWith('%%') || 
          processedLine.startsWith('flowchart') ||
          processedLine.startsWith('graph') ||
          processedLine.startsWith('sequenceDiagram') ||
          processedLine.startsWith('classDiagram')) {
        return processedLine;
      }
      
      // ä¿®å¤ä¿ç•™å…³é”®å­—é—®é¢˜ - ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…
      for (const [reserved, replacement] of Object.entries(reservedKeywords)) {
        // åˆ›å»ºå¤šä¸ªåŒ¹é…æ¨¡å¼
        const patterns = [
          // 1. åŒ¹é…è¡Œå¼€å¤´çš„ä¿ç•™å…³é”®å­—åè·Ÿæ ‡ç­¾æˆ–ç®­å¤´
          new RegExp(`^\\s*${reserved}(?=\\[|\\(|\\s*-->|\\s*---|\s*==>)`, 'i'),
          // 2. åŒ¹é…ç®­å¤´åçš„ä¿ç•™å…³é”®å­—
          new RegExp(`(-->|---|==>)\\s+${reserved}(?=\\[|\\(|\\s*$)`, 'i'),
          // 3. åŒ¹é…å•ç‹¬ä¸€è¡Œçš„ä¿ç•™å…³é”®å­—
          new RegExp(`^\\s*${reserved}\\s*$`, 'i'),
          // 4. åŒ¹é…ä¿ç•™å…³é”®å­—åè·Ÿæ ‡ç­¾çš„æƒ…å†µ
          new RegExp(`\\b${reserved}(?=\\[|\\()`, 'i')
        ];
        
        let lineChanged = false;
        patterns.forEach(pattern => {
          if (pattern.test(processedLine)) {
            console.log(`DiagramAgent: ç¬¬${index + 1}è¡Œå‘ç°ä¿ç•™å…³é”®å­— "${reserved}"ï¼Œæ›¿æ¢ä¸º "${replacement}"`);
            processedLine = processedLine.replace(pattern, (match) => {
              return match.replace(new RegExp(`\\b${reserved}\\b`, 'i'), replacement);
            });
            lineChanged = true;
            hasChanges = true;
          }
        });
        
        // å¦‚æœè¿™ä¸€è¡Œå·²ç»è¢«ä¿®æ”¹ï¼Œè·³è¿‡å…¶ä»–å…³é”®å­—æ£€æŸ¥ä»¥é¿å…é‡å¤æ›¿æ¢
        if (lineChanged) break;
      }
      
      // ä¿®å¤ç®­å¤´æ ¼å¼ - ç¡®ä¿å‰åæœ‰ç©ºæ ¼
      const originalLine = processedLine;
      processedLine = processedLine
        // å¤„ç† --> ç®­å¤´
        .replace(/(\w+|\]|\))-->/g, '$1 -->')
        .replace(/-->(\w+|\[)/g, '--> $1')
        // å¤„ç† --- ç®­å¤´
        .replace(/(\w+|\]|\))---/g, '$1 ---')
        .replace(/---(\w+|\[)/g, '--- $1')
        // å¤„ç† ==> ç®­å¤´
        .replace(/(\w+|\]|\))==>/g, '$1 ==>')
        .replace(/==>(\w+|\[)/g, '==> $1')
        // å¤„ç†æ¡ä»¶ç®­å¤´ -->|label|
        .replace(/-->\|([^|]+)\|(\w+)/g, '--> |$1| $2')
        .replace(/(\w+)\|([^|]+)\|-->/g, '$1 |$2| -->');
      
      if (originalLine !== processedLine) {
        hasChanges = true;
      }
      
      return processedLine;
    });
    
    processedCode = processedLines.join('\n');
    
    // æœ€ç»ˆæ¸…ç†
    const finalCode = processedCode
      // ç§»é™¤å¤šä½™çš„ç©ºè¡Œï¼ˆè¶…è¿‡2ä¸ªè¿ç»­ç©ºè¡Œï¼‰
      .replace(/\n\s*\n\s*\n+/g, '\n\n')
      // ç¡®ä¿ä»£ç ç»“å°¾æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªæ¢è¡Œç¬¦
      .replace(/\n*$/, '\n')
      // ç§»é™¤è¡Œå°¾ç©ºæ ¼
      .replace(/[ \t]+$/gm, '');
    
    if (hasChanges || finalCode !== code.trim() + '\n') {
      console.log('DiagramAgent: ä»£ç å·²é¢„å¤„ç†ï¼Œä¿®å¤äº†ä¿ç•™å…³é”®å­—å’Œè¯­æ³•é—®é¢˜');
      console.log('DiagramAgent: ä¿®å¤å‰:', code.substring(0, 150) + '...');
      console.log('DiagramAgent: ä¿®å¤å:', finalCode.substring(0, 150) + '...');
    }
    
    return finalCode;
  }

  /**
   * è§£æå“åº”
   */
  private parseResponse(response: string, request: DiagramGenerationRequest): DiagramGenerationResult {
    try {
      console.log('DiagramAgent: å¼€å§‹è§£æå“åº”');
      console.log('DiagramAgent: åŸå§‹å“åº”:', response.substring(0, 200) + '...');
      
      // é¦–å…ˆå°è¯•è§£æJSONå“åº”
      const jsonMatch = response.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        try {
          let jsonString = jsonMatch[0];
          console.log('DiagramAgent: æå–çš„JSONå­—ç¬¦ä¸²:', jsonString.substring(0, 100) + '...');

          // ä¿®å¤JSONä¸­çš„æ§åˆ¶å­—ç¬¦é—®é¢˜
          try {
            // ç›´æ¥è§£æï¼Œå¦‚æœå¤±è´¥åˆ™è¿›è¡Œä¿®å¤
            const parsed = JSON.parse(jsonString);
            const validated = this.validateAndCleanResponse(parsed);
            return this.buildResult(validated, request);
          } catch (parseError) {
            console.log('DiagramAgent: JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤:', (parseError as Error).message);
            
            // å°è¯•ä¿®å¤JSONå­—ç¬¦ä¸²
            const fixedJsonString = this.fixJsonString(jsonString);
            console.log('DiagramAgent: ä¿®å¤åçš„JSON:', fixedJsonString.substring(0, 100) + '...');
            
            const parsed = JSON.parse(fixedJsonString);
            const validated = this.validateAndCleanResponse(parsed);
            return this.buildResult(validated, request);
          }
        } catch (jsonError) {
          console.log('DiagramAgent: JSONè§£æå½»åº•å¤±è´¥ï¼Œå°è¯•è§£æä¸ºçº¯Mermaidä»£ç ');
        }
      }

      // å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•è§£æä¸ºçº¯Mermaidä»£ç 
      const mermaidMatch = response.match(/```mermaid\n([\s\S]*?)\n```/);
      if (mermaidMatch) {
        let mermaidCode = mermaidMatch[1];
        console.log('DiagramAgent: æ‰¾åˆ°Mermaidä»£ç å—:', mermaidCode.substring(0, 100) + '...');
        
        // åº”ç”¨é¢„å¤„ç†ï¼Œä¿®å¤ä¿ç•™å…³é”®å­—å’Œè¯­æ³•é—®é¢˜
        mermaidCode = this.preprocessMermaidCode(mermaidCode);
        
        // è‡ªåŠ¨æ£€æµ‹å›¾è¡¨ç±»å‹
        const detectedType = this.detectDiagramType(mermaidCode);
        
        return {
          mermaidCode: mermaidCode,
          explanation: 'å·²ç”ŸæˆMermaidå›¾è¡¨ä»£ç ',
          suggestions: ['å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–å›¾è¡¨ç»“æ„', 'æ·»åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯', 'è°ƒæ•´å›¾è¡¨æ ·å¼'],
          diagramType: detectedType || request.diagramType || 'flowchart',
          metadata: {
            model: this.model._llmType(),
            provider: this.getProviderName()
          }
        };
      }

      // å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯çº¯Mermaidä»£ç 
      if (response.includes('graph') || response.includes('flowchart') || response.includes('sequenceDiagram')) {
        console.log('DiagramAgent: æ£€æµ‹åˆ°çº¯Mermaidä»£ç ');
        
        // åº”ç”¨é¢„å¤„ç†ï¼Œä¿®å¤ä¿ç•™å…³é”®å­—å’Œè¯­æ³•é—®é¢˜
        let processedCode = this.preprocessMermaidCode(response.trim());
        const detectedType = this.detectDiagramType(processedCode);
        
        return {
          mermaidCode: processedCode,
          explanation: 'å·²ç”ŸæˆMermaidå›¾è¡¨ä»£ç ',
          suggestions: ['å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–å›¾è¡¨ç»“æ„', 'æ·»åŠ æ›´å¤šè¯¦ç»†ä¿¡æ¯', 'è°ƒæ•´å›¾è¡¨æ ·å¼'],
          diagramType: detectedType || request.diagramType || 'flowchart',
          metadata: {
            model: this.model._llmType(),
            provider: this.getProviderName()
          }
        };
      }

      throw new Error('æ— æ³•è¯†åˆ«å“åº”æ ¼å¼');

    } catch (error: any) {
      console.error('DiagramAgent: å“åº”è§£æå¤±è´¥', error);
      
      // æä¾›é»˜è®¤å“åº”
      return {
        mermaidCode: 'graph TD\n    A[è§£æå¤±è´¥] --> B[è¯·æ£€æŸ¥è¾“å…¥]',
        explanation: 'å“åº”è§£æå¤±è´¥ï¼Œè¯·é‡è¯•',
        suggestions: ['æ£€æŸ¥ç½‘ç»œè¿æ¥', 'é‡æ–°æè¿°éœ€æ±‚', 'å°è¯•æ›´ç®€å•çš„æè¿°'],
        diagramType: request.diagramType || 'flowchart',
        metadata: {
          model: this.model._llmType(),
          provider: this.getProviderName()
        }
      };
    }
  }

  /**
   * ä¿®å¤JSONå­—ç¬¦ä¸²ä¸­çš„æ§åˆ¶å­—ç¬¦
   */
  private fixJsonString(jsonString: string): string {
    try {
      // æ–¹æ³•1ï¼šå°è¯•æ›´ç®€å•çš„ä¿®å¤æ–¹æ³•
      // é¦–å…ˆå°è¯•ç®€å•åœ°è½¬ä¹‰æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦
      let fixed = jsonString
        .replace(/\n/g, '\\n')
        .replace(/\r/g, '\\r')
        .replace(/\t/g, '\\t');
      
      // æµ‹è¯•æ˜¯å¦èƒ½è§£æ
      JSON.parse(fixed);
      return fixed;
    } catch (error) {
      console.log('DiagramAgent: ç®€å•ä¿®å¤å¤±è´¥ï¼Œå°è¯•æ›´å¤æ‚çš„ä¿®å¤');
      
      // æ–¹æ³•2ï¼šæ›´å½»åº•çš„ä¿®å¤
      try {
        // æå–mermaidCodeå­—æ®µçš„å€¼å¹¶å•ç‹¬å¤„ç†
        const mermaidCodeMatch = jsonString.match(/"mermaidCode"\s*:\s*"([^"]*(?:\\.[^"]*)*)"(?=\s*,|\s*})/);
        if (mermaidCodeMatch) {
          const originalValue = mermaidCodeMatch[1];
          // æ­£ç¡®è½¬ä¹‰Mermaidä»£ç ä¸­çš„ç‰¹æ®Šå­—ç¬¦
          const escapedValue = originalValue
            .replace(/\\/g, '\\\\')  // è½¬ä¹‰åæ–œæ 
            .replace(/"/g, '\\"')    // è½¬ä¹‰åŒå¼•å·
            .replace(/\n/g, '\\n')   // è½¬ä¹‰æ¢è¡Œç¬¦
            .replace(/\r/g, '\\r')   // è½¬ä¹‰å›è½¦ç¬¦
            .replace(/\t/g, '\\t');  // è½¬ä¹‰åˆ¶è¡¨ç¬¦
          
          // æ›¿æ¢åŸå§‹å€¼
          const fixedJson = jsonString.replace(mermaidCodeMatch[0], `"mermaidCode": "${escapedValue}"`);
          
          // æµ‹è¯•è§£æ
          JSON.parse(fixedJson);
          return fixedJson;
        }
      } catch (error2) {
        console.log('DiagramAgent: å¤æ‚ä¿®å¤ä¹Ÿå¤±è´¥');
      }
      
      // å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²
      return jsonString;
    }
  }

  /**
   * éªŒè¯å’Œæ¸…ç†å“åº”æ•°æ®
   */
  private validateAndCleanResponse(parsed: any): any {
    // éªŒè¯å“åº”æ ¼å¼
    const schema = z.object({
      mermaidCode: z.string(),
      explanation: z.string(),
      suggestions: z.array(z.string()),
      diagramType: z.string()
    });

    return schema.parse(parsed);
  }

  /**
   * è‡ªåŠ¨æ£€æµ‹å›¾è¡¨ç±»å‹
   */
  private detectDiagramType(code: string): string {
    const trimmedCode = code.trim();
    
    // æ£€æµ‹å„ç§å›¾è¡¨ç±»å‹
    if (trimmedCode.includes('sequenceDiagram')) {
      return 'sequence';
    } else if (trimmedCode.includes('classDiagram')) {
      return 'class';
    } else if (trimmedCode.includes('erDiagram')) {
      return 'er';
    } else if (trimmedCode.includes('gitgraph')) {
      return 'gitgraph';
    } else if (trimmedCode.includes('gantt')) {
      return 'gantt';
    } else if (trimmedCode.includes('pie')) {
      return 'pie';
    } else if (trimmedCode.includes('journey')) {
      return 'journey';
    } else if (trimmedCode.includes('graph') || trimmedCode.includes('flowchart')) {
      return 'flowchart';
    }
    
    // é»˜è®¤è¿”å› flowchart
    return 'flowchart';
  }

  /**
   * éªŒè¯ Mermaid ä»£ç æ˜¯å¦åŒ…å«ä¿ç•™å…³é”®å­—
   */
  private validateMermaidCode(code: string): { isValid: boolean; issues: string[] } {
    const issues: string[] = [];
    const reservedKeywords = [
      'end', 'start', 'stop', 'class', 'state', 'note', 'loop', 'alt', 'opt', 
      'par', 'critical', 'break', 'rect', 'activate', 'deactivate', 'if', 
      'else', 'elseif', 'endif', 'and', 'or', 'not', 'true', 'false'
    ];
    
    const lines = code.split('\n');
    lines.forEach((line, index) => {
      const trimmedLine = line.trim();
      
      // è·³è¿‡ç©ºè¡Œã€æ³¨é‡Šå’Œå›¾è¡¨ç±»å‹å£°æ˜
      if (!trimmedLine || 
          trimmedLine.startsWith('%%') || 
          trimmedLine.startsWith('flowchart') ||
          trimmedLine.startsWith('graph') ||
          trimmedLine.startsWith('sequenceDiagram') ||
          trimmedLine.startsWith('classDiagram')) {
        return;
      }
      
      // æ£€æŸ¥æ˜¯å¦åŒ…å«ä¿ç•™å…³é”®å­—ä½œä¸ºèŠ‚ç‚¹ID
      reservedKeywords.forEach(keyword => {
        const patterns = [
          new RegExp(`^\\s*${keyword}(?=\\[|\\(|\\s*-->|\\s*---|\s*==>)`, 'i'),
          new RegExp(`(-->|---|==>)\\s+${keyword}(?=\\[|\\(|\\s*$)`, 'i'),
          new RegExp(`^\\s*${keyword}\\s*$`, 'i')
        ];
        
        patterns.forEach(pattern => {
          if (pattern.test(trimmedLine)) {
            issues.push(`ç¬¬${index + 1}è¡ŒåŒ…å«ä¿ç•™å…³é”®å­— "${keyword}": ${trimmedLine}`);
          }
        });
      });
    });
    
    return {
      isValid: issues.length === 0,
      issues
    };
  }

  /**
   * æ„å»ºæœ€ç»ˆç»“æœ
   */
  private buildResult(validated: any, request: DiagramGenerationRequest): DiagramGenerationResult {
    // æ¸…ç† mermaidCodeï¼Œç§»é™¤ä»£ç å—æ ‡è®°
    let cleanedMermaidCode = validated.mermaidCode;
    
    // ç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
    cleanedMermaidCode = cleanedMermaidCode
      .replace(/^```mermaid\s*\n?/i, '')  // ç§»é™¤å¼€å¤´çš„ ```mermaid
      .replace(/^```\s*\n?/i, '')        // ç§»é™¤å¼€å¤´çš„ ```
      .replace(/\n?```\s*$/i, '')        // ç§»é™¤ç»“å°¾çš„ ```
      .trim();                           // ç§»é™¤å‰åç©ºç™½

    // åº”ç”¨é¢„å¤„ç†ï¼Œä¿®å¤ä¿ç•™å…³é”®å­—å’Œè¯­æ³•é—®é¢˜
    cleanedMermaidCode = this.preprocessMermaidCode(cleanedMermaidCode);

    // éªŒè¯æœ€ç»ˆä»£ç 
    const validation = this.validateMermaidCode(cleanedMermaidCode);
    if (!validation.isValid) {
      console.warn('DiagramAgent: ä»£ç éªŒè¯å‘ç°é—®é¢˜:', validation.issues);
      // å¦‚æœä»æœ‰é—®é¢˜ï¼Œå†æ¬¡å°è¯•é¢„å¤„ç†
      cleanedMermaidCode = this.preprocessMermaidCode(cleanedMermaidCode);
    }

    console.log('DiagramAgent: åŸå§‹ä»£ç :', validated.mermaidCode);
    console.log('DiagramAgent: æœ€ç»ˆå¤„ç†åä»£ç :', cleanedMermaidCode);

    return {
      mermaidCode: cleanedMermaidCode,
      explanation: validated.explanation,
      suggestions: validated.suggestions,
      diagramType: validated.diagramType,
      metadata: {
        model: this.model._llmType(),
        provider: this.getProviderName(),
        usage: this.extractUsageInfo()
      }
    };
  }

  /**
   * è·å–æä¾›å•†åç§°
   */
  private getProviderName(): string {
    const modelType = this.model._llmType();
    if (modelType === 'volcengine') return 'volcengine';
    if (modelType === 'openai') return 'openai';
    if (modelType === 'anthropic') return 'anthropic';
    if (modelType === 'qwen') return 'qwen';
    return 'unknown';
  }

  /**
   * æå–ä½¿ç”¨ä¿¡æ¯
   */
  private extractUsageInfo(): { totalTokens?: number; promptTokens?: number; completionTokens?: number } | undefined {
    // è¿™é‡Œå¯ä»¥æ ¹æ®ä¸åŒæä¾›å•†çš„å“åº”æ ¼å¼æå–tokenä½¿ç”¨ä¿¡æ¯
    return undefined;
  }

  /**
   * æ›´æ–°å¯¹è¯å†å²
   */
  private updateConversationHistory(userPrompt: string, response: string): void {
    // ç›´æ¥æ·»åŠ ç”¨æˆ·æ¶ˆæ¯å’ŒAIå›å¤
    this.conversationHistory.push(
      new HumanMessage(userPrompt),
      new AIMessage(response)
    );

    console.log('DiagramAgent: æ·»åŠ å¯¹è¯è®°å½• - ç”¨æˆ·:', userPrompt.substring(0, 50) + '...');
    console.log('DiagramAgent: æ·»åŠ å¯¹è¯è®°å½• - åŠ©æ‰‹:', response.substring(0, 50) + '...');

    // é™åˆ¶å†å²é•¿åº¦ï¼Œä¿æŒæœ€è¿‘çš„å¯¹è¯
    const maxHistoryLength = 20; // å¢åŠ å†å²é•¿åº¦ä»¥æ”¯æŒæ›´é•¿çš„å¯¹è¯
    if (this.conversationHistory.length > maxHistoryLength + 1) { // +1 for system message
      const systemMessages = this.conversationHistory.filter(msg => msg._getType() === 'system');
      const recentMessages = this.conversationHistory
        .filter(msg => msg._getType() !== 'system')
        .slice(-maxHistoryLength);
      
      this.conversationHistory = [...systemMessages, ...recentMessages];
      console.log('DiagramAgent: å¯¹è¯å†å²å·²æˆªæ–­ï¼Œä¿ç•™æœ€è¿‘', maxHistoryLength, 'æ¡æ¶ˆæ¯');
    }
  }

  /**
   * ç¡çœ å‡½æ•°
   */
  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

/**
 * Agent å·¥å‚ç±»
 */
export class DiagramAgentFactory {
  /**
   * åˆ›å»ºç«å±±å¼•æ“ Agent
   */
  static createVolcengineAgent(config: {
    apiKey: string;
    endpoint?: string;
    modelName?: string;
    temperature?: number;
    maxTokens?: number;
    enableMemory?: boolean;
  }): DiagramAgent {
    const model = new VolcengineLangChainProvider({
      apiKey: config.apiKey,
      endpoint: config.endpoint,
      modelName: config.modelName,
      temperature: config.temperature,
      maxTokens: config.maxTokens
    });

    return new DiagramAgent({
      model,
      temperature: config.temperature,
      maxTokens: config.maxTokens,
      enableMemory: config.enableMemory || false,
      retryCount: 3
    });
  }

  /**
   * åˆ›å»º OpenAI Agent
   */
  static createOpenAIAgent(config: {
    apiKey: string;
    modelName?: string;
    temperature?: number;
    maxTokens?: number;
    enableMemory?: boolean;
  }): DiagramAgent {
    const model = new ChatOpenAI({
      openAIApiKey: config.apiKey,
      modelName: config.modelName || 'gpt-4',
      temperature: config.temperature || 0.7,
      maxTokens: config.maxTokens || 2048
    });

    return new DiagramAgent({
      model,
      temperature: config.temperature,
      maxTokens: config.maxTokens,
      enableMemory: config.enableMemory || false,
      retryCount: 3
    });
  }

  /**
   * åˆ›å»º Claude Agent
   */
  static createClaudeAgent(config: {
    apiKey: string;
    modelName?: string;
    temperature?: number;
    maxTokens?: number;
    enableMemory?: boolean;
  }): DiagramAgent {
    const model = new ChatAnthropic({
      anthropicApiKey: config.apiKey,
      modelName: config.modelName || 'claude-3-sonnet-20240229',
      temperature: config.temperature || 0.7,
      maxTokens: config.maxTokens || 2048
    });

    return new DiagramAgent({
      model,
      temperature: config.temperature,
      maxTokens: config.maxTokens,
      enableMemory: config.enableMemory || false,
      retryCount: 3
    });
  }

  /**
   * åˆ›å»º Qwen Agent
   */
  static createQwenAgent(config: {
    apiKey: string;
    endpoint?: string;
    modelName?: string;
    temperature?: number;
    maxTokens?: number;
    enableMemory?: boolean;
  }): DiagramAgent {
    const model = new QwenLangChainProvider({
      apiKey: config.apiKey,
      endpoint: config.endpoint,
      modelName: config.modelName,
      temperature: config.temperature,
      maxTokens: config.maxTokens
    });

    return new DiagramAgent({
      model,
      temperature: config.temperature,
      maxTokens: config.maxTokens,
      enableMemory: config.enableMemory || false,
      retryCount: 3
    });
  }
}
